{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "3MODELS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raghunadh-eva/eva6/blob/master/S7_ASSIGNMENT/CODE3_CAPACITY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89D3tlw_dJnV"
      },
      "source": [
        "**Basic setup block**\n",
        "\n",
        "\n",
        "*   Load the required utils/libraries\n",
        "*   Setup the transformations needed to load the data\n",
        "*   Split the input data into train and test\n",
        "*   Create the train and test data objects\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2UphvIXcJ4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5b037d5-43a5-4e5a-ce40-be1629d7e44f"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, utils\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7juHzCDavqqZ",
        "outputId": "5ee824c8-a2b4-4a48-d1d3-ad6ffb48ef98"
      },
      "source": [
        "!pip install -U albumentations\n",
        "import albumentations as A\n",
        "import cv2\n",
        "\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: albumentations in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.16.2)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (4.5.2.54)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.5.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYM0Q5RKfHyR"
      },
      "source": [
        "test_transforms  = transforms.Compose([\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.4914,0.4822,0.4465), (0.247,0.2435,0.2616))\n",
        "                                       #transforms.RandomRotation((-7.0,7.0),fill=(0,)), #Ideally use mean - adding #0 since MNIST dark pixels and no-information around the borders\n",
        "                                       #transforms.ColorJitter(brightness = 0.1, contrast= 0.1, saturation = 0.1, hue =0.1)\n",
        "                                       #transforms.Resize((28,28)) #should be before converting to Tensor logically\n",
        "                                      ])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD5RlnxdxSzs"
      },
      "source": [
        "train_transforms_a = A.Compose([\n",
        "                                       A.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.2435, 0.2616)),\n",
        "                                       A.HorizontalFlip(p=0.5),\n",
        "                                       A.ShiftScaleRotate(),\n",
        "                                       A.CoarseDropout(max_holes=1,max_height=16,max_width=16,min_holes=1,min_height=16,min_width=16,fill_value=(0.4914, 0.4822, 0.4465),mask_fill_value=None),\n",
        "                                       ToTensorV2()\n",
        "                                       #transforms.Normalize((0.4914,0.4822,0.4465), (0.247,0.2435,0.2616))\n",
        "                                       #A.HorizontalFlip(0.5)\n",
        "                                       #transforms.RandomRotation((-7.0,7.0),fill=(0))\n",
        "                                       #Ideally use mean - adding #0 since MNIST dark pixels and no-information around the borders\n",
        "                                       #transforms.ColorJitter(brightness = 0.1, contrast= 0.1, saturation = 0.1, hue =0.1),\n",
        "                                       #transforms.Resize((28,28)) #should be before converting to Tensor logically\n",
        "                                       ])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oejBzxzq50tX"
      },
      "source": [
        "import cv2\n",
        "import torchvision\n",
        "\n",
        "cv2.setNumThreads(0)\n",
        "cv2.ocl.setUseOpenCL(False)\n",
        "\n",
        "class data_albumentations(datasets.CIFAR10):\n",
        "    def __init__(self, root=\"~/data/cifar10\", train=True, download=True, transform=None):\n",
        "        super().__init__(root=root, train=train, download=download, transform=transform)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.data[index], self.targets[index]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=image)\n",
        "            image = transformed[\"image\"]\n",
        "\n",
        "        return image, label\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8fMRGI4h-bV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "775316b8-fed8-4929-b029-c83d6f6d6297"
      },
      "source": [
        "#train = datasets.CIFAR10('./data', train=True,  download=True, transform=train_transforms)\n",
        "train = data_albumentations(train=True,  download=True, transform=train_transforms_a)\n",
        "test =  datasets.CIFAR10('./data', train=False, download=True, transform=test_transforms)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOstmqZoiluZ",
        "outputId": "a57694a1-43a5-46fb-ac9d-35717d66b2a5"
      },
      "source": [
        "#Always start with same random set everytime\n",
        "SEED = 1\n",
        "\n",
        "#Is GPU ?\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "print('CUDA Available?',cuda)\n",
        "\n",
        "#what happens when SEED = 2 ?\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "#set the seed for GPU device as well\n",
        "if cuda:\n",
        "  torch.cuda.manual_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=2, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "#Why change batch_size for CPU - since it should not matter\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
        "\n",
        "\n",
        "test_loader  = torch.utils.data.DataLoader(test, **dataloader_args)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "##Why shuffle=false in the example provided ?"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Available? True\n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81Z01DMclQgP"
      },
      "source": [
        "**Visualize the input data with image standardization**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW6kBIPPsAJ6"
      },
      "source": [
        "image_loader = torch.utils.data.DataLoader(train, shuffle=True,batch_size=4)\n",
        "\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    npimg[0] = (npimg[0] * 0.247) + 0.4914\n",
        "    npimg[1] = (npimg[1] * 0.2435) + 0.4822\n",
        "    npimg[2] = (npimg[2] * 0.2616) + 0.4465\n",
        "    #we can use this directly but simply converting to tensor and converting back\n",
        "    timg = torch.from_numpy(npimg)\n",
        "    nimg = timg.numpy()\n",
        "    plt.imshow(np.transpose(nimg, (1, 2, 0)))\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(image_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "#imshow(torchvision.utils.make_grid(images))\n",
        "#print(classes[labels[10]])\n",
        "#print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv3mXm9isgs6"
      },
      "source": [
        "**Visualize the input data without image standardization**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7LD-U8Mlaxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "849e2c09-f1d5-4669-b7e6-954f0fea89c0"
      },
      "source": [
        "#Comment this block from CODE2 onwards\n",
        "train_nonorm_transforms = transforms.Compose([\n",
        "                                       transforms.ToTensor()\n",
        "                                       #transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                       #transforms.RandomRotation((-7.0,7.0),fill=(0,)), #Ideally use mean - adding #0 since MNIST dark pixels and no-information around the borders\n",
        "                                       #transforms.ColorJitter(brightness = 0.1, contrast= 0.1, saturation = 0.1, hue =0.1),\n",
        "                                       #transforms.Resize((28,28)) #should be before converting to Tensor logically\n",
        "                                       ])\n",
        "test_nonorm_transforms  = transforms.Compose([\n",
        "                                       transforms.ToTensor()\n",
        "                                       #transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                       #transforms.RandomRotation((-7.0,7.0),fill=(0,)), #Ideally use mean - adding #0 since MNIST dark pixels and no-information around the borders\n",
        "                                       #transforms.ColorJitter(brightness = 0.1, contrast= 0.1, saturation = 0.1, hue =0.1)\n",
        "                                       #transforms.Resize((28,28)) #should be before converting to Tensor logically\n",
        "                                      ])\n",
        "train_nonorm = datasets.CIFAR10('./data_nonorm', train=True,  download=True, transform=train_nonorm_transforms)\n",
        "test_nonorm =  datasets.CIFAR10('./data_nonorm', train=False, download=True, transform=test_nonorm_transforms)\n",
        "train_loader_nonorm = torch.utils.data.DataLoader(train_nonorm, **dataloader_args)\n",
        "test_loader_nonorm  = torch.utils.data.DataLoader(test_nonorm, **dataloader_args)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPCPA7N-LLY2"
      },
      "source": [
        "#chsum = 0\n",
        "##pbar = tqdm(train_loader_nonorm)\n",
        "\n",
        "#for index, (data,target) in enumerate(train_loader_nonorm):\n",
        "#    chsum += data.sum(dim=(0,2,3),keepdim=True)\n",
        "\n",
        "#mean = chsum / (len(train_nonorm) * 32 *32)\n",
        "#\n",
        "#chsum = None\n",
        "#for index, (data,target) in enumerate(train_loader_nonorm):\n",
        "#  if index == 0:\n",
        "#   print(data.min(),data.max())\n",
        "#   chsum = (data - mean).pow(2).sum(dim=(0,2,3),keepdim=True)\n",
        "#  else:\n",
        "#   chsum += (data - mean).pow(2).sum(dim=(0,2,3),keepdim=True)\n",
        "\n",
        "#std = torch.sqrt(chsum/(len(train_nonorm) * 32 * 32))\n",
        "#print(\"Traindata Mean\",mean)\n",
        "#print(\"Traindata std dev\",std)\n",
        "\n",
        "#chsum = 0\n",
        "#from tqdm import tqdm\n",
        "#pbar = tqdm(test_loader_nonorm)\n",
        "\n",
        "#for index, (data,target) in enumerate(test_loader_nonorm):\n",
        "#    chsum += data.sum(dim=(0,2,3),keepdim=True)\n",
        "\n",
        "#mean = chsum / (len(test_nonorm) * 32 *32)\n",
        "\n",
        "#chsum = None\n",
        "#for index, (data,target) in enumerate(test_loader_nonorm):\n",
        "#  if index == 0:\n",
        "#    chsum = (data - mean).pow(2).sum(dim=(0,2,3),keepdim=True)\n",
        "#  else:\n",
        "#   chsum += (data - mean).pow(2).sum(dim=(0,2,3),keepdim=True)\n",
        "\n",
        "#std = torch.sqrt(chsum/(len(test_nonorm) * 32 * 32))\n",
        "#print(\"Test data Mean\",mean)\n",
        "#print(\"Test data std dev\",std)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "2i0FYCLFEas_",
        "outputId": "e9a658e2-9b76-4cd4-caf5-0c9c7c9e704f"
      },
      "source": [
        "dataiter = iter(train_loader_nonorm)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "def imshow_nonorm(img):\n",
        "    img = img     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    \n",
        "# show images\n",
        "imshow_nonorm(torchvision.utils.make_grid(images[10]))\n",
        "\n",
        "print(classes[labels[10]])\n",
        "#print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "horse\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbgElEQVR4nO2dbYxcZ3XH/+femdnd7DrexG84thPnDUKImhCtoqAgREHQFKEGpCqCDygfIowqIhWJfohSqaRSP0BVQKiqqEwTESpKSCGIqI1a0gg14kMDm5A4L4aSGJvErL1OvI7tfZu5955+mInYpPd/9n3W5Pn/JMuz98xz77nP3DN35vnPOcfcHUKItz7ZRjsghOgPCnYhEkHBLkQiKNiFSAQFuxCJoGAXIhEaqxlsZjcD+BqAHMA/ufsXo+cPDgz4yPBwvbEs6biiKOr3d94gHdNo8FOL5MaqqqgNqB/nwZjKuc3I/hZlJcMs2F2wPzM+MLYtf0wMHxfPcf24lboR+x/YVmRavpNTr53F9Oxc7cAVB7uZ5QD+AcCHALwM4Gdm9pC7P8/GjAwP45Y/+lCtrXztNXqsqVdO1m5/x7XvoGO27dhKbfPzbWqbm52htqrs1G7vtGf5/uamqc3CizQgeHNxNjC4SD3wo9nkl0iz2aS2Rp7Xbs/J9q4t+KBp3DYzy1/PBtln4AYs48eKbiJZMM4yfkAjL1qeB68Z2f733/p3OmY1H+NvAPCCux9y9zaA+wHcsor9CSHWkdUE+y4ALy34++XeNiHEOci6L9CZ2T4zGzez8bn5+fU+nBCCsJpgPwpgz4K/d/e2vQF33+/uY+4+NjgwsIrDCSFWw2qC/WcArjSzS82sBeATAB5aG7eEEGvNilfj3b0wszsA/Ce60tu97v5cNCbPM4yM1EtvnQ7/iH+KrCQ3Gi06ptHknyLKkmtNzWC1tUS9PGitYBU2mGKvuNwYrrhH6iBZx/cs0t64/4ODfI7zBl9hbhBbnq9sNTsLVrOHAgl2JQrbSjNBQyky8J8trefR6j6VNvlhVqWzu/vDAB5ezT6EEP1Bv6ATIhEU7EIkgoJdiERQsAuRCAp2IRJhVavxy8XdUbTrM9iKTpAUQkxlIEEFu0MRyFqlczmsJJl5VeCIBzLfiglkNCZtRckdUaZfFiauRDJa/bhGgyfPRNJbSKA3ZSSBZqXZfKEbwesS7bOq6q+RyA0jlxXL8gN0ZxciGRTsQiSCgl2IRFCwC5EICnYhEqGvq/GNRgNbt9WXizp+lpdvqljtt2iFM0juKCNb8P7H1qzZaioQJ1VE5aAiG/cEyPP640Ur3VFCS1QqKtwnWcUPV6wDWxb4YUHJKuZjHoyJ1uLj14yPW0HuUryCT/zwoECh7uxCJIKCXYhEULALkQgKdiESQcEuRCIo2IVIhL5Kb0VR4cRUvcQ2dYZ3Yml36pNnjk5M0DGvnD1DbSVpJwUAXnFbzrIPgjFRLblIkFmJnAQAjXL5HVCi+m5RV5KorFreqD+3MLmDZTwhlqGiZB02LGrZFZXrY91bgFgKjmDybLQ3JvcWQeKV7uxCJIKCXYhEULALkQgKdiESQcEuRCIo2IVIhFVJb2Z2GMAZACWAwt3Houe3OwVeOvZqrW3u1NlgYL20dXzyBB1STZ2ktkjGaUaZXESTqQI5hmV/AXGrqUjWivWr+s2NQELzqs1tgR+NjLeGYkXSPMgQjMSmqIZeFtTCY0lgM7Nc6h0I2nk1sqCdV5D2Fqpy5PoJs+iIcT4ovrgWOvsfuvsra7AfIcQ6oo/xQiTCaoPdAfzIzJ4ws31r4ZAQYn1Y7cf497r7UTPbDuARM/uFuz+28Am9N4F9ADA0OLTKwwkhVsqq7uzufrT3/ySAHwC4oeY5+919zN3HWi3eM10Isb6sONjNbNjMNr3+GMCHATy7Vo4JIdaW1XyM3wHgBz0ZqwHgX9z9PxYbxOQEC3QGVlyvE2QuWaAZ5YEOEglDZaSFUEeCooFRXlPF34ej1lbt2fna7a1m/XYAaAxyCS2aRw+y1OhtJNKggukNDxXYWGurkmQHdsdEcx+0DgszHDm2gntuVdW3IovkvxUHu7sfAnDtSscLIfqLpDchEkHBLkQiKNiFSAQFuxCJoGAXIhH6WnASMGREeolr9ZHihZEUFu0vrnq47H1GWVdRMcco+y5IpEOzwaWyXaMjtdunZnhW4aszs9S2dfQCaguzvPJm7fbR4fPpmLLg2XenAx+jrMOCqGFxT78g+y7I2ivKejkMALKojx0rihn2CVy+DKw7uxCJoGAXIhEU7EIkgoJdiERQsAuRCH1ejQfYYmYRJBGwVj0rXa3Mg4wLphYAgJNV2oIt+QLI6helAcQJECPBCn/hfNV3ktSTe+HYJB1z+rX6uoAAMPiuQWobGDyP2or5+rqB7WleNxAlX43vBPX6mi2uTlTstQ6uj7Lg8+skAQUAyqANWKQYZKTVV5ggQ3en9k9CJI+CXYhEULALkQgKdiESQcEuRCIo2IVIhL5Kb+4OZzJV2BWo/j0pqvmVRTky0bGCRAdDfVLLa2d4ksl8O2iWE9Q6G7vkEmrLcj7u6Yl6ie3USe7HzBxPMpk6dYbatm/npcGZenV6lu+vCKS34cFN1GZBiy2mUGVBUTsnNQ+7xuCa46OQBck1rJVTUXXoGLa3SHLWnV2IRFCwC5EICnYhEkHBLkQiKNiFSAQFuxCJsKj0Zmb3AvgogEl3v6a37UIA3wWwF8BhALe6+9Ri+xpo5bh452itrXM+d8U7O+q3D/CUskbQRNJITbuujXN2tl4KOXz8GB1z8gSXvKzBJaOfFjyDavf2i6ht25YttdvPnJ2mY+bm56jt+MQEtV22s/51AYDd2y+s3V4N7KZjOkFtvaE297/qcInq1Hy9rNhp8+y1RpCp2Ah1W05Ug264WZ9ZODjC5cZ2WX99jD/xc+4DtfyObwK4+U3b7gTwqLtfCeDR3t9CiHOYRYO912/95Js23wLgvt7j+wB8bI39EkKsMSv9zr7D3V//fHcM3Y6uQohzmFUv0Hn393n0i4yZ7TOzcTMbn53j3w2FEOvLSoP9uJntBIDe/7Tmkbvvd/cxdx8bGuQljoQQ68tKg/0hALf1Ht8G4Idr444QYr1YivT2HQDvB7DVzF4G8AUAXwTwgJndDuAIgFuXcrDKHW0ik0y++uY1wN/RIdLQhVu20TGbmrwYYlkGWU3lPDWdnZ6p3e4ll1VGRni7o8K59Na44FJqOw0uG80e/23t9rPTPNssYoYUjgSAX754mNqq6ddqt9tFV9Ax7S0802/wlV9Q21Xnc5m18vrX89Q0z7AbNZ7Nd2KeX6dRxtnmi7iMtuXKeq1v2+hWOmbqpfprsRHIuYsGu7t/kpg+uNhYIcS5g35BJ0QiKNiFSAQFuxCJoGAXIhEU7EIkQn8LTlaOTrteCimCPlmdsl6uKwKZrGjXSxMA4EGvtCgjrkkkryt2cgmw06jP8gOArLmH2lCepqbfHH2G2qZO1fdtsyCfb2iI/9jJgt53E6/yjL6Tp+ttrSP10iAAzHX+m9qKeZ71dmTX26jtmsvrJcz5Nv815+kiyGxr8PtjVMSyBZ5K50X9Pn2ey4M5kfmirE3d2YVIBAW7EImgYBciERTsQiSCgl2IRFCwC5EIfZXe4BW8Uy+JNS0oANioFxTOy/mYAeOyhQcyX5MnDeH8C+oLIlYVH/TSFC+GeObUC9SWFaeorZjlveWcNFkbGOQvdYvMLwBUpLAhAHSi/mVEhSrbvK/cRaObqS3PeRbjbyZ5JtrZ2XrJ7qqLttMxJ8FluS1NPo+58bnK5rhMnP22Pmuv3MqvnYzJx+r1JoRQsAuRCAp2IRJBwS5EIijYhUiE/q7GwwCrX9EeGOI1urxZv8rZDmq4lbN8pT6qFdbMgxVmVvst2N/ps/W12ADgmRf5avxAk7dCarR44srI5vq2SxduHqZjTp/kCS0OPsdhIhJJKPJgBX84qD48uonX8rtgyy5qO3Tk17Xbj53kisZFb9tJbR3j98cZktACAOU0X1n3ov4aGdrMFYM2kTui+dWdXYhEULALkQgKdiESQcEuRCIo2IVIBAW7EImwlPZP9wL4KIBJd7+mt+1uAJ8GcKL3tLvc/eHF9jXQyrF3d32yQ+VBm6Ri+TJDp1xZnTnjDWmRWX0dsRmSbAEAky/8htou3sk7Xb/9Mt7+qXB+3jt31O9z1+7ddMzkkYPUduIkT8gZf/4Qtb3z0vq6cMde5VLkmXku5V22m9dwu2QXn8dr947Ubv+fA/ycnz98mNqufzuX+baPculwoMX9H2jW33M3ncfvxQOd+ms4t9UlwnwTwM0127/q7tf1/i0a6EKIjWXRYHf3xwDwHEIhxO8Fq/nOfoeZHTCze83sgjXzSAixLqw02L8O4HIA1wGYAPBl9kQz22dm42Y2Pj3LiwIIIdaXFQW7ux9399LdKwDfAHBD8Nz97j7m7mPDQTMCIcT6sqJgN7OFmQIfB/Ds2rgjhFgvliK9fQfA+wFsNbOXAXwBwPvN7DoADuAwgM8s5WAjQ03cdM1Fy3ay3amXEwpW6AzATNA6p13wDKSi4HXEciJ5PXeES297dtRnoQHAuy7n7Z9GNw1R2/Qsr+N23iA576nDdMzOzfxYs3NcKtu1pV7WAoCxK+qlt7lLttAxz/16gtrOa/LXegjcx9HN9Zf4n9x0OR1z4NBxanvb+Vz2fOfFfB5bTT7OiFzWzF+iY7KMjMn49btosLv7J2s237PYOCHEuYV+QSdEIijYhUgEBbsQiaBgFyIRFOxCJEKfC0468opkNvFkHXi7PoOt6ARF/Npcgig73MYFHuDQ8foMsInjr9Ix77nmYmobHuBSzcwM/7VhTlo8AcA8GxcU0pwP5v7wy7wY5VUXb6O2ikiYww1+f9m7nf/qurJAugqyH534MRjMx42X8yy6MsimbM/z6xEVP17OpqTkLwyTiKuSX8G6swuRCAp2IRJBwS5EIijYhUgEBbsQiaBgFyIR+iq9zUzP4snx+mzYMiiiOE8KTlZB1lsVSCRRocoiG6C2o1Nnarc3nUt5x17mBSfnSdFAAAjcD7wHSmI9fxPvpbd5dJTaGiU/t5Ov8mKUZ07VzxWVmRCfFzJuPTjFs95aREzNs6gXIHcyz7kclkcSYNAPMCdRmAd99tpEfp2e4fKf7uxCJIKCXYhEULALkQgKdiESQcEuRCL0dTW+KktMn65fpa2C1UonWTJZkBzRyPj7WLjq256hpj0kb6URrBRnQYZPYYGaUEWZQYGNMABeJ681zdsuvWs7T9YpAskgI6vdWTRXxl+zquKqQCdIDMqz+ks8D/yIsrKiu2O32DKxBYdjl4EHKk+DXANh+zLughDirYSCXYhEULALkQgKdiESQcEuRCIo2IVIhKW0f9oD4FsAdqCrSex396+Z2YUAvgtgL7otoG5196loX3luGN1Uf0gLklqMSGyRjFMUkTwV6CDBsIokVbSafBpDOcmb3I1AxomkN2fzSFoMAUCjwW3nD0Q+chv1cQWyIQDkDT7HnaimING8wqsj8jG4dILyb2EiDHMmEgeZVB1Jiku5sxcAPu/uVwO4EcBnzexqAHcCeNTdrwTwaO9vIcQ5yqLB7u4T7v5k7/EZAAcB7AJwC4D7ek+7D8DH1stJIcTqWdZ3djPbC+DdAB4HsMPdX2+7eQzdj/lCiHOUJQe7mY0A+D6Az7n76YU2734hqf0SYWb7zGzczMan54K62kKIdWVJwW5mTXQD/dvu/mBv83Ez29mz7wQwWTfW3fe7+5i7jw0PBgs6Qoh1ZdFgt+5S+D0ADrr7VxaYHgJwW+/xbQB+uPbuCSHWiqVkvd0E4FMAnjGzp3rb7gLwRQAPmNntAI4AuHXRPbnDiEwSyWgl0zQCOSlSrvIgIy4LGkCxo3mbfz0pg8y8iGgYywIEgAaR+iyYkKLNs96KKiiGF9Rqa5D2SnlwYlHmY2cuyhCkJji5Rpo5r+8WXleBIGbBtWNRhiM57yo4FsvqjK6bRYPd3X8CLvl9cLHxQohzA/2CTohEULALkQgKdiESQcEuRCIo2IVIhL4WnHQHOu166a0R9AUqiLaSBepJGRRs9IrrE4PNoIVPVe9ju4yypLjkEslQOZGueo5QE1XKomy+wMcyyB6MWjkxuTSSDcMsxqidV3BuOXHSI0kxkLzKqKhk4Eh0VzWSmRcVMo0KWK7EByHEWwgFuxCJoGAXIhEU7EIkgoJdiERQsAuRCH2V3syArEH0srDXW73OEGU7RVKTBVlvYdFAstMqkmOipLFAu4qyq7LAxmTKqHVcJ5C18qBgZkTBEhWDMY1AivTADwtsHeIIz/MDWo3Aj/A6Da6rSCsjF0lQBxQdIomuVP4TQryFULALkQgKdiESQcEuRCIo2IVIhL6uxgOGLKs/ZCsPlq3JymMRJbuEK5ncVuVBHTGyis/OCQDyaIaDBdo8WBG26D26qJ/HCjxryIKMIlZLDuBtuQDeQom2p0JcPy0PasZZMJFsdboq+EWQR4kwgczTCc7Ng9V4NsfNZvA6k91Fr4nu7EIkgoJdiERQsAuRCAp2IRJBwS5EIijYhUiERaU3M9sD4FvotmR2APvd/WtmdjeATwM40XvqXe7+8KJHJFJIVDOOtccpI6kjcCFK7ojq0/HklMD3QOaLCBNygpOjSUORj+HBIgmQ0yG7jBI1opp2ncDHLEzWqfeydC7lzQV19yJ5kNWS644LrjkyrhNciwWTNoNrYyk6ewHg8+7+pJltAvCEmT3Ss33V3f9uCfsQQmwwS+n1NgFgovf4jJkdBLBrvR0TQqwty/rObmZ7AbwbwOO9TXeY2QEzu9fMLlhj34QQa8iSg93MRgB8H8Dn3P00gK8DuBzAdeje+b9Mxu0zs3EzG5+e462NhRDry5KC3cya6Ab6t939QQBw9+PuXrp7BeAbAG6oG+vu+919zN3Hhgeba+W3EGKZLBrs1v1l/T0ADrr7VxZs37ngaR8H8OzauyeEWCuWshp/E4BPAXjGzJ7qbbsLwCfN7Dp0dafDAD6z2I4qd8wRTaaRBRlsRO+wqD1OVHQtwII0NdaCKAt8j/SpdieQeIIkwFaDv0ez044yBLMg660MiuhFfhipyxfVuzPjfrRY7ULEshZr15QHmYpRTcGi5FrqwADfZ9TaqiKvTXR9szqEkTS4lNX4n6D+kl1cUxdCnDPoF3RCJIKCXYhEULALkQgKdiESQcEuRCL0t+CkAwVpxxMVWMyIxBMW1wvOLA/HcYnHK7bT6JeB/FhRllck1Ri4NMQSAZtRAUuLMg75RDJZCwAa5OTyQOaLunk1gtcl6OYFVsc0iwYFxTk9mI8qkCmjop4Zk5aDTEV+7ajgpBDJo2AXIhEU7EIkgoJdiERQsAuRCAp2IRKhr9KbA3AmKTWibLN6USaoN4moBmGjEUgaQVaTWb2PVfCeGWV5VZEsFyTSRQUiWcHBgSaf31bQU6w9y2XFdpuf2+BAfe0CC/TGogz6qAXHMnAbUwdDadMiaZP7GBVAjTIjWdZh1OqNFWiNCnrqzi5EIijYhUgEBbsQiaBgFyIRFOxCJIKCXYhE6Kv0lmUZzhsaqLVFxQuLTr0cNt/mslAnKNgYSV7Ru19FGreVVVCUscX3GJxySJQBxsSfTpCRhaAfXVREsQr0zXkiOXrBD5YHslweSGVlxeeDv9RhwzxuCqStTiAdOsn2BIDBVv12y4PsuzBHsB7d2YVIBAW7EImgYBciERTsQiSCgl2IRFh0Nd7MBgE8BmCg9/zvufsXzOxSAPcD2ALgCQCfcvd2uC/w6l4lWekGgDmS+OHBanCrEbTwCVZGZ4PV4iZZBQ/LmYXvp0H7qqijVLDLJlm1LoPkmciPSNWIWkqxnBDWtggAGsHqc9RGK0pAYa8ZU3gAoBMsx0ctmZqBmhC1ZaKtsgruR5tcw6tNhJkH8AF3vxbd9sw3m9mNAL4E4KvufgWAKQC3L2FfQogNYtFg9y5ne382e/8cwAcAfK+3/T4AH1sXD4UQa8JS+7PnvQ6ukwAeAfAigFPu/vpnoZcB7FofF4UQa8GSgt3dS3e/DsBuADcAuGqpBzCzfWY2bmbj0/PhV3ohxDqyrNV4dz8F4McA3gNg1H5XumU3gKNkzH53H3P3seEB8rtAIcS6s2iwm9k2MxvtPR4C8CEAB9EN+j/tPe02AD9cLyeFEKtnKYkwOwHcZ2Y5um8OD7j7v5nZ8wDuN7O/AfBzAPcstiOHo6QJEkGNMa9/T2o1A6kmIMuCWmF5fe00ADCi/0QJHFlkC2ScIpgPWlgNQPdl+v+0Wvy8qkCuCXJ80Arq2jkpohe1NGpEmUGBdJXlQT05cm5Zzn0PShSiDJJdyshHboIT2bkdHCsfHCIHChKvAh+6jrgfAPDumu2H0P3+LoT4PUC/oBMiERTsQiSCgl2IRFCwC5EICnYhEsGiLJk1P5jZCQBHen9uBfBK3w7OkR9vRH68kd83Py5x9211hr4G+xsObDbu7mMbcnD5IT8S9EMf44VIBAW7EImwkcG+fwOPvRD58Ubkxxt5y/ixYd/ZhRD9RR/jhUiEDQl2M7vZzH5pZi+Y2Z0b4UPPj8Nm9oyZPWVm43087r1mNmlmzy7YdqGZPWJmv+r9f8EG+XG3mR3tzclTZvaRPvixx8x+bGbPm9lzZvbnve19nZPAj77OiZkNmtlPzezpnh9/3dt+qZk93oub75rZ8gpEuHtf/6FbYPZFAJcBaAF4GsDV/faj58thAFs34LjvA3A9gGcXbPtbAHf2Ht8J4Esb5MfdAP6iz/OxE8D1vcebAPwvgKv7PSeBH32dE3QTekd6j5sAHgdwI4AHAHyit/0fAfzZcva7EXf2GwC84O6HvFt6+n4At2yAHxuGuz8G4OSbNt+CbuFOoE8FPIkffcfdJ9z9yd7jM+gWR9mFPs9J4Edf8S5rXuR1I4J9F4CXFvy9kcUqHcCPzOwJM9u3QT68zg53n+g9PgZgxwb6coeZHeh9zF/3rxMLMbO96NZPeBwbOCdv8gPo85ysR5HX1Bfo3uvu1wP4YwCfNbP3bbRDQPedHWHj4HXl6wAuR7dHwASAL/frwGY2AuD7AD7n7qcX2vo5JzV+9H1OfBVFXhkbEexHAexZ8DctVrneuPvR3v+TAH6Aja28c9zMdgJA7//JjXDC3Y/3LrQKwDfQpzkxsya6AfZtd3+wt7nvc1Lnx0bNSe/Yyy7yytiIYP8ZgCt7K4stAJ8A8FC/nTCzYTPb9PpjAB8G8Gw8al15CN3CncAGFvB8Pbh6fBx9mBMzM3RrGB50968sMPV1Tpgf/Z6TdSvy2q8VxjetNn4E3ZXOFwH85Qb5cBm6SsDTAJ7rpx8AvoPux8EOut+9bke3Z96jAH4F4L8AXLhBfvwzgGcAHEA32Hb2wY/3ovsR/QCAp3r/PtLvOQn86OucAPgDdIu4HkD3jeWvFlyzPwXwAoB/BTCwnP3qF3RCJELqC3RCJIOCXYhEULALkQgKdiESQcEuRCIo2IVIBAW7EImgYBciEf4P4EDLvbu2G9QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bYxdYKtQBk9"
      },
      "source": [
        "**####Batch Normalization + L1 LOSS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pSLtPQPvktt"
      },
      "source": [
        "dropout_perc = 0.05\n",
        "\n",
        "class BatchNormNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BatchNormNet, self).__init__()\n",
        "\n",
        "        #BLOCK C1\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 32 ; #Receptive field = 3x3\n",
        "\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 32; #Receptive field = 5x5\n",
        "        \n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 32; #Receptive field = 7x7\n",
        "\n",
        "        self.convblock16 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, groups=64, kernel_size=(3, 3), padding=1, dilation=2, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 32; #Receptive field = 7x7\n",
        "\n",
        "        self.convblock17 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, groups=128, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 32; #Receptive field = 7x7\n",
        "\n",
        "        self.convblock18 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, groups=256, kernel_size=(3, 3), padding=1, dilation =2 ,bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 32; #Receptive field = 7x7\n",
        "\n",
        "\n",
        "        #BLOCK C1 TRANSITION\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=16, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        ) # output_size = 32; #Receptive field = 7x7\n",
        "\n",
        "        #self.pool1 = nn.MaxPool2d(2, 2) # output_size = 16 ; #Receptive field = 8x8\n",
        "        #Drop maxPooling and use strided convolution\n",
        "        self.pool1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        )\n",
        "        #Use dilated kernels instead of Max pooling\n",
        "        #self.pool1 = nn.Sequential(\n",
        "        #    nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), dilation=2, padding=0, bias=False),\n",
        "        #    nn.BatchNorm2d(16),\n",
        "        #    nn.ReLU(),\n",
        "        #    nn.Dropout(dropout_perc),\n",
        "        #    nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), dilation=2, padding=0, bias=False),\n",
        "        #    nn.BatchNorm2d(16),\n",
        "        #    nn.ReLU(),\n",
        "        #    nn.Dropout(dropout_perc),\n",
        "        #    nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), dilation=2, padding=0, bias=False),\n",
        "        #    nn.BatchNorm2d(16),\n",
        "        #    nn.ReLU(),\n",
        "        #    nn.Dropout(dropout_perc),\n",
        "        #    nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), dilation=2, padding=0, bias=False),\n",
        "        #    nn.BatchNorm2d(16),\n",
        "        #    nn.ReLU(),\n",
        "        #   nn.Dropout(dropout_perc)\n",
        "        #    #nn.Conv2d(in_channels=64, out_channels=16, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        #)\n",
        "        #BLOCK C2\n",
        "        \n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 16; #Receptive field = 5x5\n",
        "        \n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, groups = 32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 16; #Receptive field = 5x5\n",
        "\n",
        "        self.convblock14 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, groups = 64, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 16; #Receptive field = 5x5\n",
        "        \n",
        "        self.convblock19 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, groups = 128, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 16; #Receptive field = 5x5\n",
        "        \n",
        "        self.convblock20 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, groups = 256, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 16; #Receptive field = 5x5\n",
        "\n",
        "        #BLOCK C2 TRANSITION\n",
        "        self.convblock7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=16, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        ) # output_size = 16; #Receptive field = 5x5\n",
        "        \n",
        "        #BLOCK C3\n",
        "        \n",
        "        self.convblock8 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 16; #Receptive field = 5x5\n",
        "        \n",
        "        self.convblock9 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, groups = 32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 16; #Receptive field = 5x5\n",
        "\n",
        "        self.convblock15 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, groups = 64, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 16; #Receptive field = 5x5\n",
        "\n",
        "        self.convblock21 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, groups = 128, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 16; #Receptive field = 5x5\n",
        "\n",
        "        self.convblock22 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, groups = 256, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 16; #Receptive field = 5x5\n",
        "\n",
        "        #BLOCK C3 TRANSITION\n",
        "        self.convblock10 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=16, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        ) # output_size = 16; #Receptive field = 5x5\n",
        "        \n",
        "        \n",
        "        #self.pool2 = nn.MaxPool2d(2, 2) # output_size = 8 ; #Receptive field = 8x8\n",
        "        self.pool2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        )\n",
        "        #BLOCK C4\n",
        "        \n",
        "        self.convblock11 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 8; #Receptive field = 5x5\n",
        "        \n",
        "        self.convblock12 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, groups = 32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 8; #Receptive field = 5x5\n",
        "\n",
        "        self.convblock23 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, groups =64, out_channels=128, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 8; #Receptive field = 5x5\n",
        "\n",
        "        self.convblock24 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, groups = 128, out_channels=256, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 8; #Receptive field = 5x5\n",
        "\n",
        "        self.convblock25 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, groups = 256, out_channels=512, kernel_size=(3, 3), padding=1, bias=False)\n",
        "            #nn.BatchNorm2d(128),\n",
        "            #nn.ReLU(),\n",
        "            #nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 8; #Receptive field = 5x5\n",
        "        #BLOCK C4 TRANSITION\n",
        "        #self.convblock13 = nn.Sequential(\n",
        "        #    nn.Conv2d(in_channels=64, out_channels=16, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        #) # output_size = 8; #Receptive field = 5x5\n",
        "                 \n",
        "        # OUTPUT BLOCK\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=8)\n",
        "        ) # output_size = 1\n",
        "\n",
        "        self.convblock13 = nn.Sequential(\n",
        "            nn.Linear(512,10,0)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock16(x)\n",
        "        #x = self.convblock17(x)\n",
        "        #x = self.convblock18(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.pool1(x)\n",
        "        \n",
        "        x = self.convblock5(x)\n",
        "        x = self.convblock6(x)\n",
        "        x = self.convblock14(x)\n",
        "        #x = self.convblock19(x)\n",
        "        #x = self.convblock20(x)\n",
        "        x = self.convblock7(x)\n",
        "\n",
        "        x = self.convblock8(x)\n",
        "        x = self.convblock9(x)\n",
        "        x = self.convblock15(x)\n",
        "        #x = self.convblock21(x)\n",
        "        #x = self.convblock22(x)\n",
        "        x = self.convblock10(x)\n",
        "\n",
        "        x = self.pool2(x)\n",
        "        x = self.convblock11(x)\n",
        "        x = self.convblock12(x)\n",
        "        x = self.convblock23(x)\n",
        "        x = self.convblock24(x)\n",
        "        x = self.convblock25(x)\n",
        "        x = self.gap(x)\n",
        "        \n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.convblock13(x)\n",
        "   \n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxbYtWxRvP6I",
        "outputId": "dcd05ba9-7c47-4e3c-f2d5-b3ef9a30dd73"
      },
      "source": [
        "model = BatchNormNet().to(device)\n",
        "summary(model, input_size=(3, 32, 32))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             432\n",
            "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
            "              ReLU-3           [-1, 16, 32, 32]               0\n",
            "           Dropout-4           [-1, 16, 32, 32]               0\n",
            "            Conv2d-5           [-1, 32, 32, 32]           4,608\n",
            "       BatchNorm2d-6           [-1, 32, 32, 32]              64\n",
            "              ReLU-7           [-1, 32, 32, 32]               0\n",
            "           Dropout-8           [-1, 32, 32, 32]               0\n",
            "            Conv2d-9           [-1, 64, 32, 32]          18,432\n",
            "      BatchNorm2d-10           [-1, 64, 32, 32]             128\n",
            "             ReLU-11           [-1, 64, 32, 32]               0\n",
            "          Dropout-12           [-1, 64, 32, 32]               0\n",
            "           Conv2d-13          [-1, 128, 30, 30]           1,152\n",
            "      BatchNorm2d-14          [-1, 128, 30, 30]             256\n",
            "             ReLU-15          [-1, 128, 30, 30]               0\n",
            "          Dropout-16          [-1, 128, 30, 30]               0\n",
            "           Conv2d-17           [-1, 16, 30, 30]           2,048\n",
            "           Conv2d-18           [-1, 16, 15, 15]           2,304\n",
            "      BatchNorm2d-19           [-1, 16, 15, 15]              32\n",
            "             ReLU-20           [-1, 16, 15, 15]               0\n",
            "          Dropout-21           [-1, 16, 15, 15]               0\n",
            "           Conv2d-22           [-1, 32, 15, 15]           4,608\n",
            "      BatchNorm2d-23           [-1, 32, 15, 15]              64\n",
            "             ReLU-24           [-1, 32, 15, 15]               0\n",
            "          Dropout-25           [-1, 32, 15, 15]               0\n",
            "           Conv2d-26           [-1, 64, 15, 15]             576\n",
            "      BatchNorm2d-27           [-1, 64, 15, 15]             128\n",
            "             ReLU-28           [-1, 64, 15, 15]               0\n",
            "          Dropout-29           [-1, 64, 15, 15]               0\n",
            "           Conv2d-30          [-1, 128, 15, 15]           1,152\n",
            "      BatchNorm2d-31          [-1, 128, 15, 15]             256\n",
            "             ReLU-32          [-1, 128, 15, 15]               0\n",
            "          Dropout-33          [-1, 128, 15, 15]               0\n",
            "           Conv2d-34           [-1, 16, 15, 15]           2,048\n",
            "           Conv2d-35           [-1, 32, 15, 15]           4,608\n",
            "      BatchNorm2d-36           [-1, 32, 15, 15]              64\n",
            "             ReLU-37           [-1, 32, 15, 15]               0\n",
            "          Dropout-38           [-1, 32, 15, 15]               0\n",
            "           Conv2d-39           [-1, 64, 15, 15]             576\n",
            "      BatchNorm2d-40           [-1, 64, 15, 15]             128\n",
            "             ReLU-41           [-1, 64, 15, 15]               0\n",
            "          Dropout-42           [-1, 64, 15, 15]               0\n",
            "           Conv2d-43          [-1, 128, 15, 15]           1,152\n",
            "      BatchNorm2d-44          [-1, 128, 15, 15]             256\n",
            "             ReLU-45          [-1, 128, 15, 15]               0\n",
            "          Dropout-46          [-1, 128, 15, 15]               0\n",
            "           Conv2d-47           [-1, 16, 15, 15]           2,048\n",
            "           Conv2d-48             [-1, 16, 8, 8]           2,304\n",
            "      BatchNorm2d-49             [-1, 16, 8, 8]              32\n",
            "             ReLU-50             [-1, 16, 8, 8]               0\n",
            "          Dropout-51             [-1, 16, 8, 8]               0\n",
            "           Conv2d-52             [-1, 32, 8, 8]           4,608\n",
            "      BatchNorm2d-53             [-1, 32, 8, 8]              64\n",
            "             ReLU-54             [-1, 32, 8, 8]               0\n",
            "          Dropout-55             [-1, 32, 8, 8]               0\n",
            "           Conv2d-56             [-1, 64, 8, 8]             576\n",
            "      BatchNorm2d-57             [-1, 64, 8, 8]             128\n",
            "             ReLU-58             [-1, 64, 8, 8]               0\n",
            "          Dropout-59             [-1, 64, 8, 8]               0\n",
            "           Conv2d-60            [-1, 128, 8, 8]           1,152\n",
            "      BatchNorm2d-61            [-1, 128, 8, 8]             256\n",
            "             ReLU-62            [-1, 128, 8, 8]               0\n",
            "          Dropout-63            [-1, 128, 8, 8]               0\n",
            "           Conv2d-64            [-1, 256, 8, 8]           2,304\n",
            "      BatchNorm2d-65            [-1, 256, 8, 8]             512\n",
            "             ReLU-66            [-1, 256, 8, 8]               0\n",
            "          Dropout-67            [-1, 256, 8, 8]               0\n",
            "           Conv2d-68            [-1, 512, 8, 8]           4,608\n",
            "        AvgPool2d-69            [-1, 512, 1, 1]               0\n",
            "           Linear-70                   [-1, 10]           5,120\n",
            "================================================================\n",
            "Total params: 68,816\n",
            "Trainable params: 68,816\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 11.59\n",
            "Params size (MB): 0.26\n",
            "Estimated Total Size (MB): 11.86\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghFiQ6mjQXdl"
      },
      "source": [
        "####LayerNorm Normalization + L1 LOSS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCU6KY3UQhUI"
      },
      "source": [
        "class LayerNormNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LayerNormNet, self).__init__()\n",
        "\n",
        "        # Input Block\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.GroupNorm(1,10),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 26 ; #Receptive field = 3x3\n",
        "\n",
        "        #CT1\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=10, out_channels=18, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.GroupNorm(1,18),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 24; #Receptive field = 5x5\n",
        "\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=18, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        ) # output_size = 24; #Receptive field = 5x5\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 12 ; #Receptive field = 6x6\n",
        "\n",
        "        #CT2\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.GroupNorm(1,16),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 10 ;  #Receptive field = 10x10\n",
        "\n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=20, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.GroupNorm(1,20),            \n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 8 ; #Receptive field = 14x14\n",
        "\n",
        "        self.convblock7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=20, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        ) # output_size = 8 ; #Receptive field = 14x14\n",
        "     \n",
        "        #CT3\n",
        "        self.convblock8 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=10, out_channels=32, kernel_size=(3, 3), padding=0, bias=False), \n",
        "            nn.ReLU(),\n",
        "            nn.GroupNorm(1,32),\n",
        "            nn.Dropout(dropout_perc)          \n",
        "        ) # output_size = 6 ; #Receptive field = 18x18\n",
        "                 \n",
        "        # OUTPUT BLOCK\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=6)\n",
        "        ) # output_size = 1\n",
        "\n",
        "        self.convblock9 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=10, kernel_size=(1, 1), padding=0, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.convblock6(x)\n",
        "        x = self.convblock7(x)\n",
        "        x = self.convblock8(x)\n",
        "        x = self.gap(x)        \n",
        "        x = self.convblock9(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuN00vTAQphA"
      },
      "source": [
        "**`####Group normalization network + L1 LOSS`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8RvVtzzQyGg"
      },
      "source": [
        "class GroupNormNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GroupNormNet, self).__init__()\n",
        "\n",
        "        # Input Block\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.GroupNorm(2,10),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 26 ; #Receptive field = 3x3\n",
        "\n",
        "        #CT1\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=10, out_channels=18, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.GroupNorm(3,18),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 24; #Receptive field = 5x5\n",
        "\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=18, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        ) # output_size = 24; #Receptive field = 5x5\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 12 ; #Receptive field = 6x6\n",
        "\n",
        "        #CT2\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.GroupNorm(2,16),\n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 10 ;  #Receptive field = 10x10\n",
        "\n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=20, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.GroupNorm(2,20),            \n",
        "            nn.Dropout(dropout_perc)\n",
        "        ) # output_size = 8 ; #Receptive field = 14x14\n",
        "\n",
        "        self.convblock7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=20, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        ) # output_size = 8 ; #Receptive field = 14x14\n",
        "     \n",
        "        #CT3\n",
        "        self.convblock8 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=10, out_channels=32, kernel_size=(3, 3), padding=0, bias=False), \n",
        "            nn.ReLU(),\n",
        "            nn.GroupNorm(2,32),\n",
        "            nn.Dropout(dropout_perc)          \n",
        "        ) # output_size = 6 ; #Receptive field = 18x18\n",
        "                 \n",
        "        # OUTPUT BLOCK\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=6)\n",
        "        ) # output_size = 1\n",
        "\n",
        "        self.convblock9 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=10, kernel_size=(1, 1), padding=0, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.convblock6(x)\n",
        "        x = self.convblock7(x)\n",
        "        x = self.convblock8(x)\n",
        "        x = self.gap(x)        \n",
        "        x = self.convblock9(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33qg7uBpxtYe"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "test_fail_data = []\n",
        "test_fail_target = []\n",
        "test_pred_target = []\n",
        "test_losses = []\n",
        "test_acc = []\n",
        "train_acc = []\n",
        "train_losses = []\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "\n",
        "  l1_lamda = 0.0001\n",
        "  \n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    #Cross entropy loss\n",
        "    #loss = F.nll_loss(y_pred, target)\n",
        "    loss = loss_function(y_pred,target)\n",
        "    #\n",
        "\n",
        "    ##Add L1 Loss\n",
        "    l1 = 0\n",
        "    for p in model.parameters():\n",
        "      p_tensor = torch.sum(torch.abs(p))\n",
        "      l1 += p_tensor\n",
        "\n",
        "    loss = loss + l1_lamda * l1\n",
        "    \n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "    \n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    test_fail_data = []\n",
        "    test_fail_target = []\n",
        "    test_pred_target = []\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            #print(pred,target.view_as(pred))\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            for i,x in enumerate(pred.eq(target.view_as(pred))):\n",
        "              if not x:\n",
        "                test_fail_data.append(data[i])\n",
        "                test_fail_target.append(target[i])\n",
        "                test_pred_target.append(pred[i])\n",
        "                #print(target[i])\n",
        "\n",
        "    test_losses.append(test_loss)\n",
        "    \n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))\n",
        "\n",
        "    return test_losses, test_acc, test_fail_data, test_fail_target, test_pred_target;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_4SP4-nRGKG"
      },
      "source": [
        "**####Block to pass argment and call the Model**\n",
        "\n",
        "Pass the model to be Invoked based on Input Argument"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf_rAU10xhSU"
      },
      "source": [
        "def main(input_model_type,EPOCHS):\n",
        "  if input_model_type == 0:\n",
        "    model = BatchNormNet().to(device)\n",
        "    run_train_test(model,EPOCHS,input_model_type)\n",
        "  elif input_model_type == 1:\n",
        "    model = LayerNormNet().to(device)\n",
        "    run_train_test(model,EPOCHS,input_model_type)\n",
        "  elif input_model_type == 2:\n",
        "    model = GroupNormNet().to(device)\n",
        "    run_train_test(model,EPOCHS,input_model_type)\n",
        "  else:\n",
        "    print(\"Invalid input for input_model_type\",input_model_type)\n",
        "    print(\"Supported values are 0 = Batch Norm,1 = Layer Norm,2 = Group Norm\")\n",
        "\n",
        "def run_train_test(model,EPOCHS,input_model_type):\n",
        "  summary(model, input_size=(3, 32, 32))\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    \n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    \n",
        "    test_losses, test_acc, test_fail_data, test_fail_target, test_pred_target = test(model, device, test_loader)\n",
        "  \n",
        "  #print(test_fail_data)\n",
        "  fig, axs = plt.subplots(1, 2)\n",
        "  if input_model_type == 0:\n",
        "    fig.suptitle('Model Type: Batch normalization')\n",
        "  if input_model_type == 1:\n",
        "    fig.suptitle('Model Type: Layer normalization')\n",
        "  if input_model_type == 2:\n",
        "    fig.suptitle('Model Type: Group normalization')\n",
        "  \n",
        "  axs[0].set_title('Test/Validation Loss Graph')\n",
        "  axs[0].set_xticks(np.arange(1,EPOCHS+1))\n",
        "  #axs[0].xlabel('Test/Validation Loss Graph')\n",
        "  #axs[0].ylabel('LOSS')\n",
        "  axs[1].set_title('Test/Validation Accuracy Graph')\n",
        "  axs[1].set_xticks(np.arange(1,EPOCHS+1))\n",
        "  #axs[1].xlabel('Test/Validation Accuracy Graph')\n",
        "  #axs[1].ylabel('Accuracy')\n",
        "  \n",
        "  axs[0].plot(test_losses)\n",
        "  axs[1].plot(test_acc)\n",
        "\n",
        "  test_10_images = []\n",
        "  for i in range(0,10):\n",
        "    test_10_images.append(test_fail_data[i])\n",
        "  \n",
        "  test_10_images_target = []\n",
        "  for i in range(0,10):\n",
        "    test_10_images_target.append(test_fail_target[i])\n",
        "\n",
        "  test_10_pred_target = []\n",
        "  for i in range(0,10):\n",
        "    test_10_pred_target.append(test_pred_target[i])\n",
        "  #print(test_10_images_target)\n",
        "\n",
        "  print('Actual Labels')\n",
        "  print(' '.join('%5s' % classes[test_10_images_target[j]] for j in range(0,10)))\n",
        "  print('Predicted Labels')\n",
        "  print(' '.join('%5s' % classes[test_10_pred_target[j]] for j in range(0,10)))\n",
        "  \n",
        "  grid = torchvision.utils.make_grid(torch.stack(test_10_images).cpu(), nrow=5)\n",
        "  plt.figure(figsize=(15,15))\n",
        "  plt.imshow(np.transpose(grid, (1,2,0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEXmcfDRXoGN"
      },
      "source": [
        "**####Call to main function**\n",
        "\n",
        "main(input_model_type,EPOCHS)\n",
        "\n",
        "input_model_type:\n",
        "\n",
        "Supported values are\n",
        "\n",
        "0 = Train a model with Batch normalization\n",
        "\n",
        "1 = Train a model with Layer normalization\n",
        "\n",
        "2 = Train a model with Group Normalization\n",
        "\n",
        "EPOCHS: num_epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-ScCBSfbadI"
      },
      "source": [
        "main(0,20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8i6aDg_3PTO"
      },
      "source": [
        "#\n",
        "\n",
        "#test_10_images = torch.stack(test_10_images)\n",
        "#print(test_10_images.dtype)\n",
        "##print(test_10_images)\n",
        "#grid = torchvision.utils.make_grid(torch.stack(test_fail_data), nrow=5)\n",
        "#plt.figure(figsize=(15,15))\n",
        "#plt.imshow(np.transpose(grid, (1,2,0)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}